## homework_3

Построение рекомендательной системы с помощью многоруких бандитов.

### Формулировка задания:

 - Написать свое policy, функцию, которая работает согласно спецификации ниже. Важно, чтобы это была не e-greedy, а иная полиси(UCB, Thompson sampling или что-то другое)
 - Прогнать свое полиси через *simulation* при  *n*=200k.
 - Оптимизировать свое policy так, чтобы общий регрет был ниже того, который выдает baseline.
 - Затюнить в своем полиси баланс exploration/exploitation так, чтобы минимизировать регрет при данном seed.

### Спецификация:

В файле **sim_lib.py** лежит функция *simulation* которая производит симуляцию жизненного цикла баннеров(Mortal bandits), на некотором абстрактном траффике. Ей на вход подается *policy* и *n* кол-во итераций.  *Policy* это функция со следующей спецификацией: 
* на вход получает лог исторических наблюдений. Это пандас датафрейм, где каждая строка соответствует статистике по одному баннеру, а индекс датафрейма, это номер этого баннера.
* на выходе выдает индекс в датафрейме отвечающий баннеру, который надо выбрать в текущей итерации. 

